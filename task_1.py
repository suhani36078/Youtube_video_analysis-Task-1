# -*- coding: utf-8 -*-
"""TASK 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A7w5BZEnm5goRFgZlPvjlw7vFWN37eGg
"""

!pip install pyspark

from pyspark.sql import SparkSession       #Sparksession is an entry point of the pyspark
from pyspark.sql.functions import *         # import functions for filtering

spark = SparkSession.builder \
    .appName("US YouTube Video Analysis") \
    .getOrCreate()
# to process data we create spark sessions

df = spark.read.csv('/content/USvideos.csv', header=True, inferSchema=True)
df.show(4)
# header=true(first row is columns name), inferSchema=True(to detect data type),

df.printSchema()
#this setp describe the data

#TOP 10 VIEWED VIDEOS
top_videos = df.orderBy(df['views'].desc()).select('title', 'channel_title', 'views')
top_videos.show(10, truncate=False)

#desc() means views in descending order

#MOST ACTIVE OR TRENDING CHANNELS
df.groupBy("channel_title") \    #groupby()------	Grouping rows by a column (channel/date)
    .count() \
    .orderBy("count", ascending=False) \
    .show(10, truncate=False)
       #group on the basis of channel name
   #count the number of videos
 #on the basis of the count sort in descending order
   #truncate=false means show full channel title name

#CHANNELS WITH MOST LIKED VIDEOS
df.select("title", "channel_title", "likes") \
  .orderBy("likes", ascending=False) \
  .show(10, truncate=False)





